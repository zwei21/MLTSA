{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Tensorflow training 1D potential example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Since this is a bit more advanced than the sklearn we recommend you start the other one first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defining Potentials: 100%|##########| 25/25 [00:00<00:00, 2005.00it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"First we import our dataset examples\"\"\"\n",
    "import MLTSA\n",
    "potentials = MLTSA.datasets.one_d_pot\n",
    "dataset = MLTSA.datasets.one_d_dataset\n",
    "#import MLTSA.datasets.one_d_pot as potentials\n",
    "#import MLTSA.datasets.one_d_dataset as dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#This sets the potentials, don't re-run\n",
    "total_n_pots = 25\n",
    "n_DW = 5\n",
    "relevant_DW_n = 2\n",
    "#After defining the desired parameters we define the potentials accordingly\n",
    "pots = potentials(total_n_pots, n_DW, relevant_DW_n)\n",
    "# This creates the first dataset of data.\n",
    "# It creates the mixing coefficients don't re-run\n",
    "n_features = 180\n",
    "degree_of_mixing = 2\n",
    "#We specified the number of features wanted and how much they will mix\n",
    "oneD_dataset = dataset(pots, n_features, degree_of_mixing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "This has set up our dataset for further use, since TensorFlow is more scalable and compatible with GPU calculations, we will do a more extensive search on this example. \n",
    "\n",
    "Let's generate the actual linear mixed data we will use for training.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Simulations: 100%|##########| 100/100 [00:20<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting simulation labels for the generated data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Simulation Outcomes: 100%|##########| 100/100 [00:00<00:00, 490561.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Simulations: 100%|##########| 50/50 [00:09<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting simulation labels for the generated data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Simulation Outcomes: 100%|##########| 50/50 [00:00<00:00, 349525.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#Generate the trajectories\n",
    "n_simulations = 100\n",
    "n_steps = 500\n",
    "data, ans = oneD_dataset.generate_linear(n_simulations, n_steps)\n",
    "data_val, ans_val = oneD_dataset.generate_linear(int(n_simulations/2), n_steps)\n",
    "\n",
    "#Prepare it for training\n",
    "time_frame = [30, 60] #Same time frame as the sklearn one\n",
    "X, Y = oneD_dataset.PrepareData(data, ans, time_frame, mode=\"Normal\")\n",
    "X_val, Y_val = oneD_dataset.PrepareData(data_val, ans_val, time_frame, mode=\"Normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Now that we have got the X and Y ready to fit to, we will train the model, in this example we want to train a Multi-Layer Perceptron just like the one in Sklearn, but we will use TensorFlow instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-6387412fc4d8>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-6387412fc4d8>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    import  ../../MLTSA_tensorflow.TF_old_MLP as MLP_tf\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Luckily we have an MLP set up to use\n",
    "import  MLTSA_tensorflow.TF_old_MLP as MLP_tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Let's do the splits to validate our training\n",
    "# data = [x_train, x_test, y_train, y_test]\n",
    "epoch_data = train_test_split(X, Y, test_size=0.4, stratify=Y) # We'll train on 40% of the data\n",
    "\n",
    "acc_train, acc_test, acc_val, loss = MLP_tf.tf_train(batch_size=[time_frame[1]-time_frame[0]], data=epoch_data, validation=[X_val, Y_val], mode=\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "The previous training has generated a record of the training, test and validation accuracy as well as the evolution of the loss throughout the epochs. \n",
    "\n",
    "These can be plotted to see how the model is learning the outcome. Additionally, a checkpoint of our trained model has been created and saved for us at \"model_best_accuracy.ckpt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].plot(acc_train*100, color=\"r\", label=\"Train\")\n",
    "ax[0].plot(acc_test*100, color=\"b\", label=\"Test\")\n",
    "ax[0].plot(acc_val*100, color=\"g\", label=\"Validation\")\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(loss, label=\"training loss\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can move onto trying the MLTSA for this ML model. For that we call the MLTSA() method within the tensorflow package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
